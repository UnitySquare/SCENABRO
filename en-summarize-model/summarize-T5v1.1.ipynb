{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kpbRIgt-rMdsHmaT1I88U1lvrWq1rQpW","timestamp":1706141072721},{"file_id":"1Hf8jLOXRpeI-kGPGZxxqNBQAH4Fik6aL","timestamp":1706078486255}],"gpuType":"T4","mount_file_id":"1vruzoZ2L_MsjYCCRWSiE-PuQXqq0Fkx5","authorship_tag":"ABX9TyOmbNXQpJwLciMuPdRQdtiS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install konlpy sentencepiece\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import pickle\n","import os\n","import re\n","from sklearn.model_selection import train_test_split\n","from konlpy.tag import Okt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tH07w5u2D2Dj","executionInfo":{"status":"ok","timestamp":1706142628239,"user_tz":-540,"elapsed":20594,"user":{"displayName":"롤다","userId":"00587605280025492851"}},"outputId":"68fc4c02-d112-48b7-baaa-eb390e219f30"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n","Installing collected packages: sentencepiece, JPype1, konlpy\n","Successfully installed JPype1-1.5.0 konlpy-0.6.0 sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["# 태그 단어\n","PAD = \"<PADDING>\"   # 패딩\n","STA = \"<START>\"     # 시작\n","END = \"<END>\"       # 끝\n","OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n","\n","# 태그 인덱스\n","PAD_INDEX = 0\n","STA_INDEX = 1\n","END_INDEX = 2\n","OOV_INDEX = 3\n","\n","# 데이터 타입\n","ENCODER_INPUT  = 0\n","DECODER_INPUT  = 1\n","DECODER_TARGET = 2\n","\n","# 한 문장에서 단어 시퀀스의 최대 개수\n","max_sequences = 30\n","\n","# 임베딩 벡터 차원\n","embedding_dim = 100\n","\n","# LSTM 히든레이어 차원\n","lstm_hidden_dim = 128\n","\n","# 정규 표현식 필터\n","RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")\n","\n","# Data Frame Create\n","story_df = pd.read_csv('/content/drive/MyDrive/my_ws/project/Final/Data/story.csv', encoding='cp949')\n","\n","# 1. 정규식을 사용해서 특수문자, 숫자 제거\n","# story_df의 각 열에 대해서 정규 표현식을 사용하여 문자열 치환을 수행하는 반복문입니다.\n","for i in range(10):  # 0부터 9까지의 열 인덱스\n","    story_df[str(i)] = story_df[str(i)].str.replace('[^A-Za-z가-힣ㄱ-ㅎㅏ-ㅣ ]', '')\n","\n","story_df.drop(['결론'], axis=1, inplace=True)\n","\n","# 결과를 저장할 빈 데이터프레임 리스트를 초기화합니다.\n","dataframes = []\n","\n","# story_df에서 9열까지 있다고 가정합니다 (0부터 9까지, 총 10개의 열).\n","# 0열부터 8열까지를 input으로 하고, 그 다음 열을 output으로 하는 데이터프레임을 생성합니다.\n","for i in range(9):  # 0부터 8까지 (9는 포함되지 않음)\n","    # 각 행에 대해 원하는 열을 공백으로 구분하여 합치기 위한 람다 함수를 apply 메서드에 사용합니다.\n","    input_column = story_df.iloc[:, :(i + 1)].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n","    output_column = story_df.iloc[:, i + 1]\n","\n","    # 새로운 데이터프레임을 만들고 dataframes 리스트에 추가합니다.\n","    df = pd.DataFrame({'input': input_column, 'output': output_column})\n","    dataframes.append(df)\n","\n","# 모든 데이터프레임을 세로 방향으로 합쳐서 result_df를 생성합니다.\n","result_df = pd.concat(dataframes, ignore_index=True)\n","\n","# 결과를 출력합니다.\n","result_df\n","\n","# x_data_df = result_df['input'];\n","# t_data_df = result_df['output'];\n","\n","# x_data_train, x_data_test, t_data_train, t_data_test = \\\n","# train_test_split(x_data_df,\n","#                  t_data_df,\n","#                  test_size=0.2,\n","#                  random_state=42)\n","\n","# question, answer = list(x_data_train), list(t_data_train)\n","# # 챗봇 데이터 출력\n","# for i in range(5):\n","#     print('Q : ' + question[i])\n","#     print('A : ' + answer[i])\n","#     print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"id":"dlUwSd5oECs5","executionInfo":{"status":"ok","timestamp":1706142715738,"user_tz":-540,"elapsed":538,"user":{"displayName":"롤다","userId":"00587605280025492851"}},"outputId":"31de9df8-b10b-4917-bd4f-fb4c5d28c5a9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-66dc1e2ed1af>:36: FutureWarning: The default value of regex will change from True to False in a future version.\n","  story_df[str(i)] = story_df[str(i)].str.replace('[^A-Za-z가-힣ㄱ-ㅎㅏ-ㅣ ]', '')\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                 input  \\\n","0             메모리 오브 더 스타는 과학자인 주인공 조나단의 이야기를 그린 영화입니다   \n","1             세상에서 가장 큰 도시 뉴욕에서 살던 주인공 존은 일상에 지쳐 있었습니다   \n","2     스카이라는 이름의 소녀는 평범한 가정에서 자라났지만 늘 독특한 능력을 가지고 있었습니다   \n","3    영화의 주인공인 제이크는 평범한 일상을 보내던 중 고요한 작은 마을에서 발견된 미스...   \n","4                       빛의 도시는 찬란한 미래 도시를 배경으로 한 영화입니다   \n","..                                                 ...   \n","895  마을의 평범한 청년 민호는 어느 날 우연히 숲에서 빛나는 돌을 발견한다 그 돌은 예...   \n","896  대도시에서 살아가던 한 소녀 수아는 어느 날 의문의 편지를 받게 된다 그 편지는 수...   \n","897  이야기는 작은 도시 속 평범한 가게 주인인 제임스의 일상에서 시작한다 그러던 어느 ...   \n","898  영화는 바다를 사랑하는 소녀 미나의 꿈을 그리며 시작된다 미나는 어릴 적부터 세계를...   \n","899  영화는 조용한 작가인 이든의 아파트에서 시작된다 이든은 소설을 쓰는 것을 사랑하지만...   \n","\n","                                                output  \n","0                조나단은 별들이 가진 기억을 추출할 수 있는 기계를 개발하게 됩니다  \n","1        그는 어느 날 친구에게서 고요한 시골 마을에 있는 오래된 집을 물려받게 되었습니다  \n","2    그녀는 생각을 읽는 능력을 가지고 있었는데 이는 그녀가 태어날 때부터 가지고 있던 ...  \n","3               그 곳은 현실과는 다른 황홀한 세계로 시간과 공간이 완전히 달랐습니다  \n","4              주인공은 미래 과학을 이용해 시간 여행을 하는 천재 과학자 제이크입니다  \n","..                                                 ...  \n","895                그는 모든 동료들에게 감사의 마음을 전하며 마을로 돌아가게 된다  \n","896        그녀는 도시에서의 삶에 새로운 의미를 찾게 되고 그녀의 삶은 더욱 풍요로워진다  \n","897                  그들은 유물을 안전하게 되돌려 놓고 평범한 일상으로 돌아온다  \n","898          세계에서 가장 아름다운 바다가 복원된 후 미나와 물고기는 각자의 길을 간다  \n","899         이든은 그 경험을 바탕으로 소설을 완성하며 다시 글쓰기에 대한 열정을 찾는다  \n","\n","[900 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-bb80a5da-ff42-4b3b-b622-201dec59e086\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>output</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>메모리 오브 더 스타는 과학자인 주인공 조나단의 이야기를 그린 영화입니다</td>\n","      <td>조나단은 별들이 가진 기억을 추출할 수 있는 기계를 개발하게 됩니다</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>세상에서 가장 큰 도시 뉴욕에서 살던 주인공 존은 일상에 지쳐 있었습니다</td>\n","      <td>그는 어느 날 친구에게서 고요한 시골 마을에 있는 오래된 집을 물려받게 되었습니다</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>스카이라는 이름의 소녀는 평범한 가정에서 자라났지만 늘 독특한 능력을 가지고 있었습니다</td>\n","      <td>그녀는 생각을 읽는 능력을 가지고 있었는데 이는 그녀가 태어날 때부터 가지고 있던 ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>영화의 주인공인 제이크는 평범한 일상을 보내던 중 고요한 작은 마을에서 발견된 미스...</td>\n","      <td>그 곳은 현실과는 다른 황홀한 세계로 시간과 공간이 완전히 달랐습니다</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>빛의 도시는 찬란한 미래 도시를 배경으로 한 영화입니다</td>\n","      <td>주인공은 미래 과학을 이용해 시간 여행을 하는 천재 과학자 제이크입니다</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>895</th>\n","      <td>마을의 평범한 청년 민호는 어느 날 우연히 숲에서 빛나는 돌을 발견한다 그 돌은 예...</td>\n","      <td>그는 모든 동료들에게 감사의 마음을 전하며 마을로 돌아가게 된다</td>\n","    </tr>\n","    <tr>\n","      <th>896</th>\n","      <td>대도시에서 살아가던 한 소녀 수아는 어느 날 의문의 편지를 받게 된다 그 편지는 수...</td>\n","      <td>그녀는 도시에서의 삶에 새로운 의미를 찾게 되고 그녀의 삶은 더욱 풍요로워진다</td>\n","    </tr>\n","    <tr>\n","      <th>897</th>\n","      <td>이야기는 작은 도시 속 평범한 가게 주인인 제임스의 일상에서 시작한다 그러던 어느 ...</td>\n","      <td>그들은 유물을 안전하게 되돌려 놓고 평범한 일상으로 돌아온다</td>\n","    </tr>\n","    <tr>\n","      <th>898</th>\n","      <td>영화는 바다를 사랑하는 소녀 미나의 꿈을 그리며 시작된다 미나는 어릴 적부터 세계를...</td>\n","      <td>세계에서 가장 아름다운 바다가 복원된 후 미나와 물고기는 각자의 길을 간다</td>\n","    </tr>\n","    <tr>\n","      <th>899</th>\n","      <td>영화는 조용한 작가인 이든의 아파트에서 시작된다 이든은 소설을 쓰는 것을 사랑하지만...</td>\n","      <td>이든은 그 경험을 바탕으로 소설을 완성하며 다시 글쓰기에 대한 열정을 찾는다</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>900 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb80a5da-ff42-4b3b-b622-201dec59e086')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bb80a5da-ff42-4b3b-b622-201dec59e086 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bb80a5da-ff42-4b3b-b622-201dec59e086');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f51167c0-a0bf-478b-b07e-f906a26285b6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f51167c0-a0bf-478b-b07e-f906a26285b6')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f51167c0-a0bf-478b-b07e-f906a26285b6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_fc00945d-b805-4df6-9423-8ff878df6e3f\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_fc00945d-b805-4df6-9423-8ff878df6e3f button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('result_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"sMM80rcQ3cnM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706142756226,"user_tz":-540,"elapsed":26997,"user":{"displayName":"롤다","userId":"00587605280025492851"}},"outputId":"bb5f61e4-907c-46ca-a774-45c4b4295a30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":3}],"source":["import pandas as pd\n","import torch\n","from transformers import T5TokenizerFast, T5ForConditionalGeneration, AdamW\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, Dataset\n","\n","# 디바이스 설정\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# 인풋 앞에 요약 붙여서 학습되도록 함\n","prefix = \"summarize: \"\n","\n","# 데이터셋 클래스 정의\n","class CustomDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length=128):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        questions = self.data.iloc[idx]['input']\n","        answers = self.data.iloc[idx]['output']\n","\n","        # 토큰 수를 max_length에 맞춰서 자르거나 패딩\n","        inputs = self.tokenizer(prefix+questions, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n","        labels = self.tokenizer(answers, max_length=self.max_length, truncation=True, padding='max_length', return_tensors='pt')\n","\n","        return {\n","            'input_ids': inputs.input_ids[0],\n","            'labels': labels.input_ids[0]\n","        }\n","\n","# 데이터 로드 및 전처리\n","df = result_df\n","\n","# 토크나이저와 모델 로드\n","model_name = \"/content/drive/MyDrive/my_ws/project/Final/t5-v1_1-base\"  # 구글드라이브\n","# model_name = \"google/t5-v1_1-base\"  # 직접다운로드\n","\n","tokenizer = T5TokenizerFast.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","model.to(device)\n","\n"]},{"cell_type":"code","source":["# 학습 설정\n","optimizer = AdamW(model.parameters(), lr=1e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","num_epochs = 1\n","log_interval = 100\n","checkpoint_interval = 0.5  # 0.5 에폭마다 체크포인트 저장\n","\n","# DataLoader를 사용하여 데이터 로드\n","batch_size = 4\n","dataset = CustomDataset(df, tokenizer)\n","data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# 학습 루프에서 데이터 로더 사용\n","total_steps = 0\n","for epoch in range(num_epochs):\n","    for batch in tqdm(data_loader, total=len(data_loader)):\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # 모델 학습\n","        outputs = model(input_ids=input_ids, labels=labels)\n","        loss = outputs.loss\n","\n","        # 역전파 및 가중치 업데이트\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_steps += 1\n","\n","        # 0.5 에폭마다 체크포인트 저장\n","        if total_steps % int(len(dataset) / (batch_size * 2)) == 0:\n","            checkpoint_dir = f\"checkpoint_{total_steps}\"\n","            model.save_pretrained(checkpoint_dir)\n","\n","# 학습이 완료된 모델 저장\n","model.save_pretrained(\"2save\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iHp3S2_SpPe4","executionInfo":{"status":"ok","timestamp":1706141706768,"user_tz":-540,"elapsed":85507,"user":{"displayName":"롤다","userId":"00587605280025492851"}},"outputId":"e5b1a2ab-7d24-4680-98c8-5f63f2cdad2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","100%|██████████| 225/225 [01:16<00:00,  2.93it/s]\n"]}]},{"cell_type":"code","source":["\n","user_input = \"바나나\"\n","\n","prompt = f\"{user_input}\"\n","input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n","\n","logits = model.generate(\n","        input_ids,\n","        max_length=1024,\n","        temperature=0.5,\n","        no_repeat_ngram_size=6,\n","        do_sample=True,\n","        num_return_sequences=1,\n","    )\n","text = tokenizer.batch_decode(logits, skip_special_tokens=True)[0]\n","\n","print(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDkQJvfZIvW9","executionInfo":{"status":"ok","timestamp":1706141828118,"user_tz":-540,"elapsed":3935,"user":{"displayName":"롤다","userId":"00587605280025492851"}},"outputId":"50ba690e-1627-44f4-fb93-9e8f398b39ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["and   ...   –   :   )  !   a  ?   0   5)  .   o   1).   -   /   wiki   —  ,   & \n"]}]}]}